{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61b8d69",
   "metadata": {},
   "source": [
    "# üìä Comparative Visualization of Balanced Accuracy, FNR, and FPR Across Subpopulations\n",
    "\n",
    "This visualization presents a comparative bar chart illustrating model performance across diverse subpopulations and dataset splits. The figure is crafted to highlight disparities and trends in **Balanced Accuracy**, **False Negative Rate (FNR)**, and **False Positive Rate (FPR)** using clear visual encodings and statistical overlays.\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Chart Structure & Interpretation\n",
    "\n",
    "#### ‚úÖ **Metric Display**\n",
    "- The **y-axis** represents performance values in percentage (%).\n",
    "- Metrics include:\n",
    "  - **Balanced Accuracy**\n",
    "  - **False Negative Rate (FNR)**\n",
    "  - **False Positive Rate (FPR)**\n",
    "\n",
    "#### üë• **X-Axis Grouping**\n",
    "- The **x-axis** is grouped into four key cohorts:\n",
    "  - **All**: Overall model performance across all populations.\n",
    "  - **NHW**: Non-Hispanic White\n",
    "  - **NHA**: Non-Hispanic African American\n",
    "  - **Hispanic**: Hispanic/Latino individuals\n",
    "\n",
    "#### üü© **Bar Segmentation & Color Coding**\n",
    "Each group displays three bars representing the performance of:\n",
    "- **NHW** ‚Äì shaded in **light blue** (`#c6dbef`)\n",
    "- **NHA** ‚Äì shaded in **light orange/tan** (`#f2d0a9`)\n",
    "- **Hispanic** ‚Äì shaded in **light green** (`#c5e8b7`)\n",
    "\n",
    "This enables comparison **within** and **between** groups.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Data Partition Visualization\n",
    "\n",
    "#### üìÇ **Training vs. Test Split**\n",
    "- **Solid border**: Performance on **Training** data\n",
    "- **Dashed border**: Performance on **Test** data\n",
    "\n",
    "This border styling encodes data partition while maintaining consistent color usage.\n",
    "\n",
    "#### üìè **Error Bars**\n",
    "- Error bars denote the **Standard Error of the Mean (SEM)**, indicating confidence in performance estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Statistical Significance Overlay\n",
    "\n",
    "- **P-value annotations** are displayed above group comparisons:\n",
    "  - `p < 0.05` indicates a **statistically significant** difference.\n",
    "  - `NS` (Not Significant) denotes no statistically meaningful difference.\n",
    "- Visual annotation lines are used to connect comparisons directly.\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Aggregate Insights (Optional Overlay)\n",
    "\n",
    "A shaded grey rectangle highlights summary statistics:\n",
    "- **Avg**: Mean performance across subgroups within a category.\n",
    "- **AvD**: Average absolute difference between subgroup performances (disparity measure).\n",
    "\n",
    "These annotations offer quick interpretability of central trends and fairness variability.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/Codes/ad_classification\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import viz_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_dir = '/home/Codes/ad_classification'\n",
    "groups   = [1, 2, 3, 4]\n",
    "legends  = ['NHW', 'NHA', 'HISP']\n",
    "datasets = ['Training', 'Training', 'Training',\n",
    "            'Training', 'Test', 'Test',\n",
    "            'Test', 'Training', 'Test',\n",
    "            'Test', 'Test', 'Training']\n",
    "\n",
    "metric_ = ['ba','fnr','fpr']\n",
    "metric_title = ['Balanced Accuracy', 'FNR', 'FPR']\n",
    "method_name  = 'xgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_0355PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_0406PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_0435PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_0454PM_Mar242025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB + KMM',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_kmm_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f652d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_cr_1025PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_cr_1046PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_cr_1125PM_Mar242025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_cr_1148PM_Mar242025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB + CR',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_cr_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c811c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [105, 4, 9, 105+int(9*2/3), 105+int(9/3), 115],\n",
    "    [65, 4, 9, 65+int(9*2/3), 65+int(9/3), 80],\n",
    "    [55, 4, 9, 55+int(9*2/3), 55+int(9/3), 70],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_kmm_cr_0830AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_kmm_cr_0841AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_kmm_cr_0911AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_kmm_cr_0929AM_Mar252025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value, metric=metric_title[i], title='XGB + KMM + CR',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_kmm_cr_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_harm_1239AM_Mar262025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_harm_0100AM_Mar262025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_harm_0139AM_Mar262025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_harm_0201AM_Mar262025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB + Harm',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_harm_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7376ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [105, 4, 9, 105+int(9*2/3), 105+int(9/3), 115],\n",
    "    [65, 4, 9, 65+int(9*2/3), 65+int(9/3), 80],\n",
    "    [55, 4, 9, 55+int(9*2/3), 55+int(9/3), 70],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_harm_0401PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_harm_0411PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_harm_0442PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_harm_0500PM_Mar252025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value, metric=metric_title[i], title='XGB + KMM + Harm',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_kmm_harm_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [105, 4, 9, 105+int(9*2/3), 105+int(9/3), 115],\n",
    "    [65, 4, 9, 65+int(9*2/3), 65+int(9/3), 80],\n",
    "    [55, 4, 9, 55+int(9*2/3), 55+int(9/3), 70],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_harm_cr_0918PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_harm_cr_0939PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_harm_cr_1018PM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_harm_cr_1041PM_Mar252025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value, metric=metric_title[i], title='XGB + CR + Harm',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_cr_harm_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f06f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [105, 4, 9, 105+int(9*2/3), 105+int(9/3), 115],\n",
    "    [65, 4, 9, 65+int(9*2/3), 65+int(9/3), 80],\n",
    "    [55, 4, 9, 55+int(9*2/3), 55+int(9/3), 70],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_kmm_harm_cr_1112AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_kmm_harm_cr_1122AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_kmm_harm_cr_1152AM_Mar252025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_kmm_harm_cr_1211PM_Mar252025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value, metric=metric_title[i], title='XGB + KMM + CR + Harm',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_kmm_cr_harm_04142025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b30de",
   "metadata": {},
   "source": [
    "#### PLot for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_dir = '/home/Codes/ad_classification'\n",
    "groups   = [1, 2, 3, 4]\n",
    "legends  = ['NHW', 'NHA', 'HISP']\n",
    "datasets = ['Training', 'Training', 'Training',\n",
    "            'Training', 'Test', 'Test',\n",
    "            'Test', 'Training', 'Test',\n",
    "            'Test', 'Test', 'Training']\n",
    "\n",
    "metric_ = ['ba','fnr','fpr']\n",
    "metric_title = ['Balanced Accuracy', 'FNR', 'FPR']\n",
    "method_name  = 'svm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0826PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0836PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0852PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0852PM_Apr282025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='SVM',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_05072025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_harm_1001PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_harm_1012PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_harm_1030PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_harm_1030PM_Apr282025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='SVM + Harm',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_harm_05072025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_cr_0927PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_cr_0937PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_cr_0953PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_cr_0953PM_Apr282025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='SVM + CR',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_cr_05072025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "list_paths = [\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_0901PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_0909PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_0911PM_Apr282025.pkl',\n",
    "    f'{source_dir}/results/{method_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_0912PM_Apr282025.pkl'\n",
    "]\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result(list_paths, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='SVM + KMM',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_kmm_05072025.png\",\n",
    "                plot_avg=True, font_weight='semibold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a443944",
   "metadata": {},
   "source": [
    "### New data loading\n",
    "Load results from saved CSV for each scenario per fold in format: `scenario_<scenario_name>_fold_<fold_number>_predict.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_dir = '/home/Codes/ad_classification'\n",
    "groups   = [1, 2, 3, 4]\n",
    "legends  = ['NHW', 'NHA', 'HISP']\n",
    "datasets = ['Training', 'Training', 'Training',\n",
    "            'Training', 'Test', 'Test',\n",
    "            'Test', 'Training', 'Test',\n",
    "            'Test', 'Test', 'Training']\n",
    "\n",
    "metric_ = ['ba','fnr','fpr']\n",
    "metric_title = ['Balanced Accuracy', 'FNR', 'FPR']\n",
    "method_name  = 'xgb'\n",
    "scenarios = ['all', 'nhw', 'nha', 'hisp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = rf'{source_dir}/results/{method_name}_objective_v2_1B/'\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "    \n",
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [82, 4.7, 15, 82+int(15*1.8/3), 82+int(15/5.5), 'grey', 10, 95],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result_from_csv(out_dir, scenarios, 10, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB + RegAlign',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_regalign_04162025.png\",\n",
    "                plot_avg=True, font_weight='semibold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = rf'{source_dir}/results/{method_name}_objective_v2_2B/'\n",
    "\n",
    "if not os.path.exists(f\"{source_dir}/images/{method_name}_new\"):\n",
    "    os.makedirs(f\"{source_dir}/images/{method_name}_new\")\n",
    "    \n",
    "configs = [\n",
    "    [93, 4.7, 16, 93+int(16*2/3), 93+int(16/4.5), 'grey', 10, 110],\n",
    "    [102, 4.7, 18, 102+int(18*2/3), 102+int(18/4.5), 'grey', 10, 120],\n",
    "    [40, 4.7, 9, 40+int(10*2/3), 40+int(10/3.5), 'grey', 0, 50],\n",
    "]\n",
    "\n",
    "for i in range(len(metric_)):\n",
    "    # Generate performance results\n",
    "    performance, error, p_value = vu.generate_result_from_csv(out_dir, scenarios, 10, metric=metric_[i])\n",
    "\n",
    "    # Plot the results\n",
    "    vu.plot_bar_chart(performance, error, groups, datasets, legends, configs[i],\n",
    "                p_value=None, metric=metric_title[i], title='XGB + SSDA',\n",
    "                save_path=f\"{source_dir}/images/{method_name}_new/{metric_[i]}_{method_name}_ssda_04162025.png\",\n",
    "                plot_avg=True, font_weight='semibold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970818b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "377416c2",
   "metadata": {},
   "source": [
    "# üîÄ Pareto Front Visualization: Fairness vs. Performance Trade-off\n",
    "\n",
    "This visualization captures the **trade-off between model performance and fairness**, offering insights into how different methods or subgroups balance these critical objectives.\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ Axis Definitions\n",
    "\n",
    "- **üü¶ X-Axis ‚Äì Fairness Metric**  \n",
    "  Represents a fairness discrepancy score (e.g., **FPR Discrepancy**, **Equalized Odds**, etc.).  \n",
    "  - üîª **Lower values** indicate better fairness (closer to equity across groups).\n",
    "\n",
    "- **üü© Y-Axis ‚Äì Performance Metric**  \n",
    "  Denotes the **overall balanced accuracy** of the model.  \n",
    "  - üî∫ **Higher values** indicate better predictive performance.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Key Plot Elements\n",
    "\n",
    "#### üîπ **Data Points and Grouping**\n",
    "- Each point reflects the **average fairness vs. performance** across folds.\n",
    "- Grouping is determined by:\n",
    "  - `centroid_type = 'method'` ‚Üí Grouped by algorithm/method (e.g., Base, CR, KMM, Harmonized).\n",
    "  - `centroid_type = 'group'` ‚Üí Grouped by data subpopulation (e.g., All, NHW, NHA, Hispanic).\n",
    "- Different **marker shapes and colors** distinguish between the groupings.\n",
    "\n",
    "#### üî∏ **Confidence Ellipses**\n",
    "- Ellipses encapsulate the variability of each group‚Äôs performance across folds.\n",
    "- Computed using a fixed **number of standard deviations (n_std)**.\n",
    "- Help visualize **stability** of each method or subgroup.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê Centroid & Ideal Point\n",
    "\n",
    "- **Centroid**: The average (mean) position of each group or method‚Äôs data points.\n",
    "- **Ideal Point**:  \n",
    "  Defined as the theoretical **best** combination:\n",
    "  - **Lowest fairness discrepancy** (far left),\n",
    "  - **Highest performance** (top).\n",
    "- A **dashed line** connects the **closest centroid** to the ideal point, indicating the most balanced trade-off.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Pareto Front\n",
    "\n",
    "- The **Pareto front** is shown in **thick gray**.\n",
    "- It highlights models that are **Pareto-optimal**‚Äîno other model outperforms them in **both** fairness and performance.\n",
    "- Useful for identifying models with optimal trade-offs without sacrificing too much in either direction.\n",
    "\n",
    "---\n",
    "\n",
    "### üîΩ Directional Guidance\n",
    "\n",
    "- **‚¨Ü Upward Arrow**: Indicates that higher performance is better.\n",
    "- **‚¨Ö Leftward Arrow**: Indicates that lower fairness discrepancy (i.e., improved fairness) is desirable.\n",
    "\n",
    "---\n",
    "\n",
    "This visualization offers a powerful lens for evaluating and selecting models that **balance fairness and performance**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/Codes/ad_classification\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import viz_utils as vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'svm'\n",
    "if model_name=='xgb':\n",
    "    list_paths = [\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_0355PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_0406PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_0435PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_0454PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_cr_1025PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_cr_1046PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_cr_1125PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_cr_1148PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_harm_1239AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_harm_0100AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_harm_0139AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_harm_0201AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_kmm_cr_0830AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_kmm_cr_0841AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_kmm_cr_0911AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_kmm_cr_0929AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_harm_0401PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_harm_0411PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_harm_0442PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_harm_0500PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_harm_cr_0918PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_harm_cr_0939PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_harm_cr_1018PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_harm_cr_1041PM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_kmm_harm_cr_1112AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_kmm_harm_cr_1122AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_kmm_harm_cr_1152AM_Mar252025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_kmm_harm_cr_1211PM_Mar252025.pkl',\n",
    "    ]\n",
    "elif model_name=='svm':\n",
    "    list_paths = [\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_none_1058PM_Jan062025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_none_0118AM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_none_0356AM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_none_0356AM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_none_0902PM_Jan072025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_none_1125PM_Jan072025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_none_0207AM_Jan082025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_none_0208AM_Jan082025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_kmm_0448PM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_kmm_0558PM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_kmm_0605PM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_kmm_0605PM_Jan072025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_none_0729PM_Jan102025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_none_1039PM_Jan102025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_none_0217AM_Jan112025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_none_0217AM_Jan112025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_kmm_1112PM_Jan082025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_kmm_1204AM_Jan092025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_kmm_1214AM_Jan092025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_kmm_1214AM_Jan092025_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_kmm_0155AM_Jan132025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_kmm_0246AM_Jan132025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_kmm_0256AM_Jan132025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_kmm_0256AM_Jan132025_harmonized.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_none_0814PM_Jan092025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_none_1117PM_Jan092025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_none_0257AM_Jan102025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_none_0258AM_Jan102025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-All_rate_0_kmm_0523PM_Jan092025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHW_rate_0_kmm_0631PM_Jan092025_harmonized_cr.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}/NCvsDem_train-NHA_rate_0_kmm_0641PM_Jan092025_harmonized_cr.pkl',\n",
    "        fr'/hehome/Codesnryho/ad_classification/results/{model_name}/NCvsDem_train-Hispanic_rate_0_kmm_0641PM_Jan092025_harmonized_cr.pkl',\n",
    "    ]\n",
    "\n",
    "results_ba   = vu.compute_performance(list_paths, metric='ba')\n",
    "results_fair = vu.compute_performance(list_paths, metric='fpr')\n",
    "\n",
    "results_avg_ba   = results_ba.groupby(['Model', 'Scenario'], as_index=False)[[\"NHW\", \"NHA\", \"Hisp\"]].mean()\n",
    "results_avg_fair = results_fair.groupby(['Model', 'Scenario'], as_index=False)[[\"NHW\", \"NHA\", \"Hisp\"]].mean()\n",
    "results_avg_ba['Pred_ba_avg']   = results_avg_ba[['NHW', 'NHA', 'Hisp']].mean(axis=1)\n",
    "results_avg_fair['Pred_fair_avg'] = (abs(results_avg_fair['NHW'] - results_avg_fair['NHA']) + abs(results_avg_fair['NHW'] - results_avg_fair['Hisp']) + abs(results_avg_fair['NHA'] - results_avg_fair['Hisp'])) / 3\n",
    "methods = results_avg_ba['Model'].values\n",
    "groups  = results_avg_ba['Scenario'].values\n",
    "performance = np.array([results_avg_ba['Pred_ba_avg'].values, results_avg_fair['Pred_fair_avg'].values]) * 100\n",
    "\n",
    "centroid_type = 'method'\n",
    "fair_metric = 'FPR Discripancy'\n",
    "if fair_metric == 'SEDF':\n",
    "    fig_config = [5, 60, 58, 6, 1.3, 0.6, 59, 58, -12, 0.6, 1.4, 48.5]\n",
    "elif fair_metric == 'EOD':\n",
    "    fig_config = [3, 25, 23, 6, 0.5, 0.6, 23.3, 23, -5.5, 0.6, 0.6, 18]\n",
    "elif fair_metric == 'GEOD':\n",
    "    fig_config = [2, 20, 18, 6, 0.5, 0.6, 18.3, 18, -5, 0.6, 0.4, 14]\n",
    "elif fair_metric == 'FNR Discripancy':\n",
    "    fig_config = [-1, 25, 22, 6, 0.5, 0.6, 22.5, 22, -7, 0.6, 0.4, 15.5]\n",
    "elif fair_metric == 'FPR Discripancy':\n",
    "    fig_config = [-2, 27, 22, 6, 0.4, 0.4, 22.5, 22, -6, 0.5, 0.5, 15.5]\n",
    "\n",
    "vu.plot_fit_central_pareto_front(performance, methods, groups, fig_config, centroid_type, metric_titles=[\"Balanced Accuracy\", \"FPR Discrepancy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xgb'\n",
    "if model_name=='xgb':\n",
    "    list_paths = [\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_0355PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_0406PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_0435PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_0454PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_cr_1025PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_cr_1046PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_cr_1125PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_cr_1148PM_Mar242025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_harm_1239AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_harm_0100AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_harm_0139AM_Mar262025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_harm_0201AM_Mar262025.pkl',\n",
    "    ]\n",
    "    results_ba   = vu.compute_performance(list_paths, metric='ba')\n",
    "    results_fair = vu.compute_performance(list_paths, metric='fnr')\n",
    "\n",
    "    list_dirs = [\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_objective_v2_2B',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_objective_v2_1B',\n",
    "    ]\n",
    "\n",
    "    results_ba_new   = vu.compute_performance_new(list_dirs, metric='ba')\n",
    "    results_fair_new   = vu.compute_performance_new(list_dirs, metric='fnr')\n",
    "\n",
    "    combined_ba = pd.concat([results_ba, results_ba_new], ignore_index=True)\n",
    "    combined_fair = pd.concat([results_fair, results_fair_new], ignore_index=True)\n",
    "elif model_name=='svm':\n",
    "    list_paths = [\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0826PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0836PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0852PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0852PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_kmm_0901PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_kmm_0909PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_kmm_0911PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_kmm_0912PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.05_none_cr_0927PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.05_none_cr_0953PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.05_none_cr_0937PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.05_none_cr_0953PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-All_rate_0_alpha_0.0_none_harm_1001PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_harm_1012PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_harm_1030PM_Apr282025.pkl',\n",
    "        fr'/home/Codes/ad_classification/results/{model_name}_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_harm_1030PM_Apr282025.pkl',\n",
    "    ]\n",
    "    combined_ba   = vu.compute_performance(list_paths, metric='ba')\n",
    "    combined_fair = vu.compute_performance(list_paths, metric='fpr')\n",
    "\n",
    "results_avg_ba   = combined_ba.groupby(['Model', 'Scenario'], as_index=False)[[\"NHW\", \"NHA\", \"HISP\"]].mean()\n",
    "results_avg_fair = combined_fair.groupby(['Model', 'Scenario'], as_index=False)[[\"NHW\", \"NHA\", \"HISP\"]].mean()\n",
    "results_avg_ba['Pred_ba_avg']   = results_avg_ba[['NHW', 'NHA', 'HISP']].mean(axis=1)\n",
    "results_avg_fair['Pred_fair_avg'] = (abs(results_avg_fair['NHW'] - results_avg_fair['NHA']) + abs(results_avg_fair['NHW'] - results_avg_fair['HISP']) + abs(results_avg_fair['NHA'] - results_avg_fair['HISP'])) / 3\n",
    "methods = results_avg_ba['Model'].values\n",
    "groups  = results_avg_ba['Scenario'].values\n",
    "performance = np.array([results_avg_ba['Pred_ba_avg'].values, results_avg_fair['Pred_fair_avg'].values]) * 100\n",
    "\n",
    "centroid_type = 'group'\n",
    "fair_metric = 'FPR Discripancy'\n",
    "if fair_metric == 'FNR Discripancy':\n",
    "    fig_config = [-2, 21, 19, 16.5, 0.4, 0.4, 19.5, 19, -10, 0.6, 0.45, 10.5]\n",
    "elif fair_metric == 'FPR Discripancy':\n",
    "    fig_config = [-2, 21, 19, 16.5, 0.4, 0.4, 19.5, 19, -10, 0.6, 0.45, 10.5]\n",
    "\n",
    "vu.plot_fit_central_pareto_front(performance, methods, groups, fig_config, centroid_type, metric_titles=[\"Balanced Accuracy\", fair_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f22df",
   "metadata": {},
   "source": [
    "# üìä SHAP Reliability and Precision Visualization for Brain Regions\n",
    "\n",
    "This notebook visualizes SHAP value reliability and precision across key brain regions in a dementia classification task. The analysis leverages a **streaming approach** to process large-scale bootstrapped SHAP outputs efficiently and identify **bilateral (left-right) brain regions** with the most consistent and informative SHAP profiles.\n",
    "\n",
    "### üß† Objective\n",
    "To identify pairs of brain regions with the most **reliable and precise SHAP contributions** using bootstrapped model interpretations, and visualize how SHAP values change with the associated structural brain volume.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Workflow Overview\n",
    "\n",
    "#### **1. Load Dataset and Extract Unique Samples**\n",
    "- Load a pickle file that contains training and group-specific (NHW, NHA, HWA) datasets across multiple folds.\n",
    "- Merge folds to build a unique dataset (`X_all_unique`) based on subject IDs.\n",
    "- Map sample IDs to (fold, row) locations for later SHAP aggregation.\n",
    "\n",
    "#### **2. List Bootstrap SHAP Files**\n",
    "- Use streaming to iteratively process SHAP value files.\n",
    "- Files are named with `iter_<n>.pkl`, sorted by iteration number.\n",
    "\n",
    "#### **3. Compute Feature-Level SHAP Metrics**\n",
    "- For each brain volume feature:\n",
    "  - Extract valid (non-outlier) samples using IQR filtering.\n",
    "  - Compute SHAP reliability (inverse coefficient of variation) and SHAP precision (inverse CI width).\n",
    "  - Aggregate metrics across bootstrap iterations.\n",
    "- Rank features by composite reliability-precision score.\n",
    "\n",
    "#### **4. Select Paired Brain Regions**\n",
    "- Use `brain_regions` dictionary to find bilateral anatomical pairs (e.g., left/right hippocampus).\n",
    "- From all valid pairs, select top-K pairs based on average composite score.\n",
    "\n",
    "#### **5. Aggregate and Bin SHAP Values for Visualization**\n",
    "- For each top feature:\n",
    "  - Aggregate SHAP values across folds and bootstrap iterations.\n",
    "  - Bin subjects by brain volume and average their SHAP values.\n",
    "  - Smooth mean and confidence intervals with LOWESS.\n",
    "\n",
    "#### **6. Plot Results**\n",
    "- Visualize top region pairs with:\n",
    "  - X-axis: volume of the region\n",
    "  - Y-axis: binned SHAP value\n",
    "  - Overlay: smoothed mean SHAP and 95% CI\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Notes\n",
    "- **Reliability** reflects stability of SHAP values across bootstraps.\n",
    "- **Precision** reflects tightness of confidence interval for the SHAP estimate.\n",
    "- **Binning** helps smooth out subject variability and supports interpretable SHAP trends.\n",
    "\n",
    "This visualization aids in understanding which brain regions contribute consistently to model decisions and supports **trustworthy interpretation of SHAP explanations** in medical imaging AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3899ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/Codes/ad_classification\")\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from viz_utils import (\n",
    "    load_dataset_unique,\n",
    "    get_bootstrap_file_list,\n",
    "    compute_feature_stats,\n",
    "    select_paired_features,\n",
    "    plot_top_pairs,\n",
    "    plot_partial_dependence_single_region,\n",
    "    brain_regions  # imported from viz_utils\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl'\n",
    "BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_all'\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_white_single'\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_black_single'\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_hisp_single'\n",
    "NBINS = 200         \n",
    "TOP_K = 9          \n",
    "IQR_FACTOR = 1.2\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1. LOAD DATASET & UNIQUE SAMPLES\n",
    "# ---------------------------\n",
    "print(\"Loading dataset ...\")\n",
    "X_all_unique, id2fold_rows, X_folds_list, feature_names = load_dataset_unique(DATA_PKL_PATH)\n",
    "print(\"Unique samples obtained:\", X_all_unique.shape[0])\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2. GET BOOTSTRAP FILES\n",
    "# ---------------------------\n",
    "file_list = get_bootstrap_file_list(BOOTSTRAP_DIR)\n",
    "print(\"Number of bootstrap files:\", len(file_list))\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3. COMPUTE METRICS FOR ALL FEATURES\n",
    "# ---------------------------\n",
    "print(\"Computing metrics for all features ...\")\n",
    "df_stats = compute_feature_stats(X_all_unique, feature_names, file_list, IQR_FACTOR, NBINS)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4. SELECT PAIRS OF FEATURES FOR VISUALIZATION\n",
    "# ---------------------------\n",
    "print(\"Selecting paired features ...\")\n",
    "paired_features = select_paired_features(df_stats, brain_regions, TOP_K)\n",
    "print(\"Top pairs selected:\")\n",
    "print(paired_features[['region', 'L_feature', 'R_feature']].to_string(index=False))\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5. VISUALIZE TOP PAIRS\n",
    "# ---------------------------\n",
    "print(\"Plotting top pairs ...\")\n",
    "plot_top_pairs(df_stats, paired_features, feature_names, X_all_unique, X_folds_list, file_list, IQR_FACTOR, NBINS, id2fold_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f99755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\"\"\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_all'\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_white_single'\n",
    "# DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl'\n",
    "# BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_black_single'\n",
    "DATA_PKL_PATH = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "BOOTSTRAP_DIR = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_hisp_single'\n",
    "STORED_DIR = r'/home/Codes/ad_classification/images/partial_plot/hisp/data'\n",
    "#region_key = '49'\n",
    "list_regions = list(brain_regions.keys())\n",
    "\n",
    "for region_key in list_regions:\n",
    "    plot_partial_dependence_single_region(\n",
    "        region_key=region_key,\n",
    "        brain_regions=brain_regions,\n",
    "        DATA_PKL_PATH=DATA_PKL_PATH,\n",
    "        BOOTSTRAP_DIR=BOOTSTRAP_DIR,\n",
    "        NBINS=500,\n",
    "        IQR_FACTOR=1.5,\n",
    "        save_path=\"/home/Codes/ad_classification/images/partial_plot/hisp\",\n",
    "        stored_data_dir=STORED_DIR,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b155cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51de3e5f",
   "metadata": {},
   "source": [
    "## SHAP Confidence Interval Visualization for Brain Region Features\n",
    "\n",
    "This analysis provides a comprehensive framework for computing and visualizing SHAP value distributions across brain regions using bootstrap resampling. The process is designed to assess the **reliability** and **precision** of SHAP importance scores across different structural brain features, categorized by tissue type and anatomical subregion.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Objective\n",
    "\n",
    "- **Quantify** model explanations using bootstrapped SHAP values across brain features.\n",
    "- **Group** features into anatomical categories (Ventricles, White Matter, and Gray Matter subregions).\n",
    "- **Visualize** the confidence intervals of SHAP values using error bar plots.\n",
    "- **Interpret** results based on model attribution stability and region-level importance.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Pipeline Steps\n",
    "\n",
    "#### 1. Load and Aggregate SHAP Bootstraps\n",
    "- Load `N` bootstrap `.pkl` files from a specified directory.\n",
    "- Each file contains SHAP values across 10 folds.\n",
    "- Compute mean SHAP values per feature, per iteration.\n",
    "- Stack all iterations to form a matrix of shape `(iterations, num_features)`.\n",
    "\n",
    "#### 2. Compute Confidence Intervals\n",
    "- From the bootstrapped matrix:\n",
    "  - Calculate the **mean**, **2.5th**, and **97.5th** percentiles.\n",
    "  - These values define the **95% Confidence Interval** for each feature's SHAP importance.\n",
    "\n",
    "#### 3. Map Feature IDs to Brain Region Labels\n",
    "- Use a predefined `brain_regions` dictionary to assign anatomical labels to feature indices.\n",
    "\n",
    "#### 4. Group Features by Brain Regions\n",
    "- Organize features into main tissue types:\n",
    "  - **Ventricles (VN)**\n",
    "  - **White Matter (WM)**\n",
    "  - **Gray Matter (GM)** with subgroups:\n",
    "    - Subcortical\n",
    "    - Frontal\n",
    "    - Temporal\n",
    "    - Parietal/Cerebellum\n",
    "    - Occipital\n",
    "    - Other\n",
    "\n",
    "#### 5. Plot SHAP Confidence Intervals\n",
    "- For each group/subgroup:\n",
    "  - Plot mean SHAP values with error bars representing 95% CI.\n",
    "  - Highlight:\n",
    "    - `y = 0` as a red dashed reference line.\n",
    "    - Optional thresholds (¬±0.05) as soft thresholds.\n",
    "  - Annotate axes with brain region names and SHAP units.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Output\n",
    "\n",
    "- **Multiple plots**, one per group/subgroup, displaying:\n",
    "  - Mean SHAP contribution per feature.\n",
    "  - Error bars showing statistical uncertainty.\n",
    "- Helps identify:\n",
    "  - Stable and important features.\n",
    "  - Noisy or non-contributing regions.\n",
    "  - Anatomical patterns in model attribution.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/Codes/ad_classification\")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from viz_utils import (\n",
    "    brain_regions,\n",
    "    load_boot_feature_means,\n",
    "    compute_confidence_intervals,\n",
    "    get_feature_labels,\n",
    "    group_feature_indices,\n",
    "    plot_group_results,\n",
    "    plot_subgroup_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca365f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_all'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_white_single'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_black_single'\n",
    "pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_hisp_single'\n",
    "num_iterations = 5000\n",
    "train_scenario = 'hisp'\n",
    "save_dir = '/home/Codes/ad_classification/images/CI_plots/'\n",
    "\n",
    "if not os.path.exists(os.path.join(save_dir, train_scenario)):\n",
    "    os.makedirs(os.path.join(save_dir, train_scenario))\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 1. LOAD DATASET & EXTRACT FEATURE NAMES\n",
    "# ---------------------------\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    train, nhw, nha, hwa, est = pickle.load(f)\n",
    "\n",
    "feature_names = list(nhw[0]['data'].iloc[:, 1:].columns)\n",
    "feature_labels = get_feature_labels(feature_names, brain_regions)\n",
    "\n",
    "num_features = len(feature_names)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 2. AGGREGATE BOOTSTRAP SHAP VALUES\n",
    "# ---------------------------\n",
    "boot_feature_means = load_boot_feature_means(bootstrap_dir, num_iterations, num_features)\n",
    "mean_values, lower_ci, upper_ci = compute_confidence_intervals(boot_feature_means)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 3. GROUP FEATURES\n",
    "# ---------------------------\n",
    "main_groups, gm_subgroups = group_feature_indices(feature_labels)\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 4. PLOT RESULTS FOR MAIN GROUPS\n",
    "# ---------------------------\n",
    "for group_name, indices in main_groups.items():\n",
    "    if indices:\n",
    "        plot_group_results(group_name, indices, mean_values, lower_ci, upper_ci, feature_labels,\n",
    "                           save_path=os.path.join(save_dir, train_scenario, f\"{group_name}_CI.png\"))\n",
    "\n",
    "# ---------------------------\n",
    "# STEP 5. PLOT RESULTS FOR Gray Matter Subgroups\n",
    "# ---------------------------\n",
    "for subgroup_name, indices in gm_subgroups.items():\n",
    "    if indices:\n",
    "        plot_subgroup_results(subgroup_name, indices, mean_values, lower_ci, upper_ci, feature_labels,\n",
    "                              save_path=os.path.join(save_dir, train_scenario, f\"{subgroup_name}_CI.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8831a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57aedf7",
   "metadata": {},
   "source": [
    "## üß† SHAP-Based Brain Region Visualization from Bootstrapped Interpretability Maps\n",
    "\n",
    "This pipeline performs an advanced interpretability analysis on a medical imaging model by mapping **bootstrapped SHAP values** onto brain regions. It filters class-specific relevance and produces detailed SHAP overlays on MNI brain templates.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objective\n",
    "\n",
    "- Compute SHAP-based attribution scores over brain regions using bootstrap iterations.\n",
    "- Filter SHAP values by prediction class (`DX=0` or `DX=1`).\n",
    "- Convert attribution vectors into brain-space using ROI-level templates.\n",
    "- Visualize normalized SHAP overlays per tissue type (GM, WM, VN).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Pipeline Overview\n",
    "\n",
    "#### 1. Load SHAP Bootstraps\n",
    "- Read `bootstrap_shap_iter_*.pkl` files (each contains 10-fold SHAPs).\n",
    "- For each iteration:\n",
    "  - Compute mean SHAP per feature (filtered by class and valid indices).\n",
    "  - Stack results into a `(iterations √ó features)` matrix.\n",
    "\n",
    "#### 2. Label Filtering and Aggregation\n",
    "- Use `DX` and `PRED_DX` to match true/predicted class (e.g., `DX=0` & `PRED=1`).\n",
    "- Apply IQR filtering per feature to remove outliers.\n",
    "- Compute:\n",
    "  - Mean SHAP values across iterations\n",
    "  - 2.5th and 97.5th percentiles ‚Üí 95% CI\n",
    "\n",
    "#### 3. Build Anatomical Brain Maps\n",
    "- Map SHAP values to brain-space using:\n",
    "  - ROI IDs from `feature_names`\n",
    "  - Region lookup from `MUSE_levels.csv`\n",
    "  - Voxel masks from `MUSE_level_*.nii.gz`\n",
    "- Create NIfTI SHAP volumes for:\n",
    "  - All significant ROIs\n",
    "  - Subsets: Gray Matter, White Matter, Ventricles\n",
    "\n",
    "#### 4. Normalize and Mask SHAP Volumes\n",
    "- Normalize each SHAP image to range [-1, 1]\n",
    "- Optionally mask non-positive values\n",
    "- Maintain consistent `vmin`, `vmax`, and color scales\n",
    "\n",
    "#### 5. Visualize Brain Maps\n",
    "- Use `nilearn.plot_stat_map()` to render:\n",
    "  - Z-axis slices (e.g., `cut_coords = [-30, -25, ..., 40]`)\n",
    "  - Custom smoothed colormap\n",
    "  - Semi-transparent overlays\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Output\n",
    "\n",
    "- SHAP brain overlays for:\n",
    "  - `All ROIs`\n",
    "  - `Gray Matter only`\n",
    "  - `White Matter only`\n",
    "  - `Ventricular structures`\n",
    "- Sliced anatomical views showing regions with high attribution\n",
    "- Optional reversal for negative SHAP visualization (e.g., class 0)\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇ Files Used\n",
    "\n",
    "- `bootstrap_shap_iter_*.pkl` ‚Üí SHAP iterations\n",
    "- `NCvsDem_train-*.pkl` ‚Üí Training metadata\n",
    "- `MNI152_T1_1mm_brain_LPS_filled.nii` ‚Üí Brain template\n",
    "- `MUSE_level_*.nii.gz` ‚Üí ROI voxel templates\n",
    "- `MUSE_levels.csv` ‚Üí ROI ID ‚Üî Level mapping\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Ideal Applications\n",
    "\n",
    "- Explainable AI in neurodiagnostics\n",
    "- Identifying predictive brain regions for classification tasks\n",
    "- Visualization of stable vs. noisy model contributions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a61374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/Codes/ad_classification\")\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from viz_utils import (\n",
    "    brain_regions,\n",
    "    get_valid_indices,\n",
    "    custom_normalize,\n",
    "    visualize_roi_map,\n",
    "    convert_to_template,\n",
    "    normalize_image,\n",
    "    mask_positive\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_all'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_white_single'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_black_single'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl'\n",
    "bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_hisp_single'\n",
    "pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "num_iterations = 5000\n",
    "desired_class = 1\n",
    "train_group = \"HISP\"\n",
    "if desired_class:\n",
    "    reverse = False\n",
    "    status = \"Dementia Prediction\"\n",
    "else:\n",
    "    reverse = False\n",
    "    status = \"NC Prediction\"\n",
    "cut_coords = [-30, -25, -20, -15, -10, -5, 0, 10, 20, 30, 40]\n",
    "scale_value = 1\n",
    "\n",
    "# Load dataset and extract feature names (assuming features start at column 1)\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    train, nhw, nha, hwa, est = pickle.load(f)\n",
    "feature_names = list(nhw[0]['data'].iloc[:, 1:].columns)\n",
    "\n",
    "# ---------------------------\n",
    "# Build valid indices, ground truth, and prediction folds.\n",
    "# ---------------------------\n",
    "y_folds, y_pred_folds, valid_folds = [], [], []\n",
    "y_label = 'DX'\n",
    "y_pred_label = 'PRED_DX'\n",
    "for i in range(10):\n",
    "    X_data = pd.concat([nhw[i]['data'], nha[i]['data'], hwa[i]['data']], axis=0)\n",
    "    valid_indices = []\n",
    "    for j in range(1, X_data.shape[1]):\n",
    "        valid_indices.append(get_valid_indices(X_data.iloc[:, j].values, factor=1.2))\n",
    "    y_data = pd.concat([nhw[i]['y'][y_label], nha[i]['y'][y_label], hwa[i]['y'][y_label]], axis=0)\n",
    "    y_pred_data = pd.concat([nhw[i]['y'][y_pred_label], nha[i]['y'][y_pred_label], hwa[i]['y'][y_pred_label]], axis=0)\n",
    "    y_folds.append(y_data)\n",
    "    y_pred_folds.append(y_pred_data)\n",
    "    valid_folds.append(valid_indices)\n",
    "\n",
    "# ---------------------------\n",
    "# Bootstrap Aggregation\n",
    "# ---------------------------\n",
    "num_features = len(feature_names)\n",
    "boot_feature_means = np.empty((num_iterations, num_features))\n",
    "for i in tqdm(range(num_iterations), desc=\"Processing bootstrap iterations\"):\n",
    "    filename = f'bootstrap_shap_iter_{i+1}.pkl'\n",
    "    with open(os.path.join(bootstrap_dir, filename), 'rb') as f:\n",
    "        shap_values_fold = pickle.load(f)  # List of 10 folds\n",
    "    fold_means = []\n",
    "    for j, fold in enumerate(shap_values_fold):\n",
    "        feature_means = []\n",
    "        for k in range(num_features):\n",
    "            valid_idx = valid_folds[j][k]\n",
    "            y_vals = y_folds[j].iloc[valid_idx].values\n",
    "            y_preds = (np.asarray(y_pred_folds[j].iloc[valid_idx].values > 0.5)).astype(int)\n",
    "            if not reverse:\n",
    "                desired_mask = (y_vals == desired_class) & (y_preds == desired_class)\n",
    "            else:\n",
    "                desired_mask = (y_vals == desired_class) & (y_preds == np.abs(1 - desired_class))\n",
    "            filtered_idx = np.array(valid_idx)[desired_mask]\n",
    "            if len(filtered_idx) > 0:\n",
    "                mean_val = np.mean(fold.iloc[filtered_idx, k])\n",
    "            else:\n",
    "                mean_val = np.mean(fold.iloc[valid_idx, k])\n",
    "            feature_means.append(mean_val)\n",
    "        fold_means.append(feature_means)\n",
    "    iteration_mean = np.mean(fold_means, axis=0)\n",
    "    boot_feature_means[i, :] = iteration_mean\n",
    "\n",
    "if desired_class == 0:\n",
    "    boot_feature_means = -boot_feature_means\n",
    "\n",
    "shap_values = np.mean(boot_feature_means, axis=0)\n",
    "lower_ci = np.percentile(boot_feature_means, 2.5, axis=0)\n",
    "upper_ci = np.percentile(boot_feature_means, 97.5, axis=0)\n",
    "\n",
    "# ---------------------------\n",
    "# Setup for Brain Map Visualization\n",
    "# ---------------------------\n",
    "muse_dir = r'/home/Codes/image_processing/plot_MUSEroi'\n",
    "df_muse = pd.read_csv(os.path.join(muse_dir, 'MUSE_levels.csv'))\n",
    "template = nib.load(os.path.join(muse_dir, \"MNI152_T1_1mm_brain_LPS_filled.nii\"))\n",
    "\n",
    "lower_threshold = 0\n",
    "upper_threshold = 0\n",
    "selected_features = [\n",
    "    (int(feature_names[i]), i)  # wrap in a list so that each element is iterable\n",
    "    for i in range(len(feature_names))\n",
    "    if lower_ci[i] > lower_threshold or upper_ci[i] < upper_threshold\n",
    "]\n",
    "\n",
    "selected_all_features = [\n",
    "    str(si[0])\n",
    "    for si in selected_features\n",
    "    if ((not reverse and shap_values[si[1]] > 0) or (reverse and shap_values[si[1]] < 0))\n",
    "       and (str(si[0]) in brain_regions)\n",
    "]\n",
    "\n",
    "selected_gm_features = [\n",
    "    str(si[0])\n",
    "    for si in selected_features\n",
    "    if ((not reverse and shap_values[si[1]] > 0) or (reverse and shap_values[si[1]] < 0)) and (str(si[0]) in brain_regions) and (\"GM\" in brain_regions[str(si[0])])\n",
    "]\n",
    "\n",
    "selected_wm_features = [\n",
    "    str(si[0])\n",
    "    for si in selected_features\n",
    "    if ((not reverse and shap_values[si[1]] > 0) or (reverse and shap_values[si[1]] < 0)) and (str(si[0]) in brain_regions) and (\"WM\" in brain_regions[str(si[0])])\n",
    "]\n",
    "\n",
    "selected_vn_features = [\n",
    "    str(si[0])\n",
    "    for si in selected_features\n",
    "    if ((not reverse and shap_values[si[1]] > 0) or (reverse and shap_values[si[1]] < 0)) and (str(si[0]) in brain_regions) and (\"VN\" in brain_regions[str(si[0])])\n",
    "]\n",
    "\n",
    "# Create SHAP maps for different region types\n",
    "q_shap_all = convert_to_template(shap_values, selected_all_features, feature_names, muse_dir, df_muse)\n",
    "q_shap_gm = convert_to_template(shap_values, selected_gm_features, feature_names, muse_dir, df_muse)\n",
    "q_shap_wm = convert_to_template(shap_values, selected_wm_features, feature_names, muse_dir, df_muse)\n",
    "q_shap_vn = convert_to_template(shap_values, selected_vn_features, feature_names, muse_dir, df_muse)\n",
    "\n",
    "normalized_img_all, max_all = normalize_image(q_shap_all, scale_val=scale_value)\n",
    "normalized_img_gm, _ = normalize_image(q_shap_gm, scale_val=scale_value, max_val=max_all)\n",
    "normalized_img_wm, _ = normalize_image(q_shap_wm, scale_val=scale_value, max_val=max_all)\n",
    "normalized_img_vn, _ = normalize_image(q_shap_vn, scale_val=scale_value, max_val=max_all)\n",
    "\n",
    "masked_img_all = mask_positive(normalized_img_all, reverse=reverse)\n",
    "masked_img_gm = mask_positive(normalized_img_gm, reverse=reverse)\n",
    "masked_img_wm = mask_positive(normalized_img_wm, reverse=reverse)\n",
    "masked_img_vn = mask_positive(normalized_img_vn, reverse=reverse)\n",
    "\n",
    "# Create custom colormap\n",
    "if reverse:\n",
    "    colors = [\n",
    "        (1, 1, 1, 0.0),\n",
    "        (0.1, 0.1, 0.9, 0.2),\n",
    "        (0.1, 0.1, 0.9, 0.5),\n",
    "        (0.1, 0.1, 0.9, 0.8),\n",
    "        (0.1, 0.1, 0.9, 1.0)\n",
    "    ]\n",
    "else:\n",
    "    colors = [\n",
    "        (1, 1, 1, 0.0),\n",
    "        (0.9, 0.1, 0.1, 0.2),\n",
    "        (0.9, 0.1, 0.1, 0.5),\n",
    "        (0.9, 0.1, 0.1, 0.8),\n",
    "        (0.9, 0.1, 0.1, 1.0)\n",
    "    ]\n",
    "smoothed_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_smooth\", colors, N=256)\n",
    "smoothed_cmap.set_under(\"none\")\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization: Display Brain Maps\n",
    "# ---------------------------\n",
    "save_dir = '/home/Codes/ad_classification/images/SHAP_maps/'\n",
    "if not os.path.exists(os.path.join(save_dir, train_group)):\n",
    "    os.makedirs(os.path.join(save_dir, train_group))\n",
    "\n",
    "visualize_roi_map(\n",
    "    masked_img_all,\n",
    "    template,\n",
    "    vmin=1e-6,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap=smoothed_cmap,\n",
    "    title=f\"SHAP Map (All Regions) trained on {train_group} - {status}\",\n",
    "    save_path=os.path.join(save_dir, train_group, f\"SHAP_map_all_{status}.png\")\n",
    ")\n",
    "\n",
    "visualize_roi_map(\n",
    "    masked_img_gm,\n",
    "    template,\n",
    "    vmin=1e-6,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap=smoothed_cmap,\n",
    "    title=f\"SHAP Map (GM) trained on {train_group} - {status}\",\n",
    "    save_path=os.path.join(save_dir, train_group, f\"SHAP_map_gm_{status}.png\")\n",
    ")\n",
    "\n",
    "visualize_roi_map(\n",
    "    masked_img_wm,\n",
    "    template,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap=smoothed_cmap,\n",
    "    title=f\"SHAP Map (WM) trained on {train_group} - {status}\",\n",
    "    save_path=os.path.join(save_dir, train_group, f\"SHAP_map_wm_{status}.png\")\n",
    ")\n",
    "\n",
    "visualize_roi_map(\n",
    "    masked_img_vn,\n",
    "    template,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap=smoothed_cmap,\n",
    "    title=f\"SHAP Map (VN) trained on {train_group} - {status}\",\n",
    "    save_path=os.path.join(save_dir, train_group, f\"SHAP_map_vn_{status}.png\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4e19e",
   "metadata": {},
   "source": [
    "#### All classes with bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(r\"/home/Codes/ad_classification\") \n",
    "\n",
    "import os \n",
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nibabel as nib \n",
    "from joblib import Parallel, delayed \n",
    "from tqdm import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from viz_utils import ( \n",
    "    brain_regions,\n",
    "    normalize_image,\n",
    "    mask_positive,\n",
    "    cast_to_float32,\n",
    "    get_valid_folds_and_labels,\n",
    "    convert_to_template, \n",
    "    simple_compute_bootstrap_iteration,\n",
    "    create_binary_map,\n",
    "    coregister_to_template,\n",
    "    visualize_roi_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Data --- \n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-All_rate_0_alpha_0.0_none_0204PM_Mar242025.pkl' \n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_all' \n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHW_rate_0_alpha_0.0_none_0226PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_white_single'\n",
    "# pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-NHA_rate_0_alpha_0.0_none_0307PM_Mar242025.pkl'\n",
    "# bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_black_single'\n",
    "pkl_path = r'/home/Codes/ad_classification/results/xgb_new/NCvsDem_train-Hispanic_rate_0_alpha_0.0_none_0331PM_Mar242025.pkl'\n",
    "bootstrap_dir = r'/media/henry-ho/DATA_8TB1/NACC/results/shap_values/xgb_hisp_single'\n",
    "muse_dir = r'/home/Codes/image_processing/plot_MUSEroi' \n",
    "output_dir = r'/home/Codes/ad_classification/results/shap_map' \n",
    "num_iterations = 5000 \n",
    "train_group = \"HISP\"  # should be ALL, NHW, NHA, or HISP\n",
    "\n",
    "ale_features = [\"31\",\"47\",\"48\",\"55\",\"170\",\"171\",\"194\",\"200\"]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "with open(pkl_path, 'rb') as f: \n",
    "    train, nhw, nha, hwa, est = pickle.load(f) \n",
    "\n",
    "y_folds, y_pred_folds, valid_folds, feature_names = get_valid_folds_and_labels(nhw, nha, hwa) \n",
    "\n",
    "results = Parallel(n_jobs=8)( \n",
    "    delayed(simple_compute_bootstrap_iteration)(i, bootstrap_dir, valid_folds, feature_names) \n",
    "    for i in tqdm(range(num_iterations), desc=\"Bootstrapping\") \n",
    "\n",
    ") \n",
    "boot_feature_means = np.array(results)\n",
    "\n",
    "# --- Compute SHAP statistics --- \n",
    "shap_values = np.mean(boot_feature_means, axis=0) \n",
    "lower_ci = np.percentile(boot_feature_means, 2.5, axis=0) \n",
    "upper_ci = np.percentile(boot_feature_means, 97.5, axis=0) \n",
    "\n",
    "# --- Select ROIs --- \n",
    "selected_features = [ \n",
    "    str(feature_names[i]) \n",
    "    for i in range(len(feature_names)) \n",
    "    if lower_ci[i] > 0 or upper_ci[i] < 0\n",
    "]\n",
    "\n",
    "selected_indices = [\n",
    "    i for i in range(len(feature_names))\n",
    "    if lower_ci[i] > 0 or upper_ci[i] < 0\n",
    "]\n",
    "\n",
    "selected_all_features_dem = [\n",
    "    str(feature_names[i])\n",
    "    for i in selected_indices\n",
    "    if (shap_values[i] > 0) and (str(feature_names[i]) in ale_features)\n",
    "]\n",
    "\n",
    "selected_all_features_nc = [\n",
    "    str(feature_names[i])\n",
    "    for i in selected_indices\n",
    "    if (shap_values[i] < 0) and (str(feature_names[i]) in ale_features)\n",
    "]\n",
    "\n",
    "# --- Final steps: map and save --- \n",
    "df_muse = pd.read_csv(os.path.join(muse_dir, 'MUSE_levels.csv'))\n",
    "\n",
    "q_shap_img_dem = convert_to_template(shap_values, selected_all_features_dem, feature_names, muse_dir, df_muse)\n",
    "q_shap_img_nc = convert_to_template(shap_values, selected_all_features_nc, feature_names, muse_dir, df_muse)\n",
    "max_val = max(abs(q_shap_img_dem.get_fdata().max()), abs(q_shap_img_nc.get_fdata().max()))\n",
    "\n",
    "q_shap_nomalized_dem, _ = normalize_image(q_shap_img_dem, max_val=max_val)\n",
    "q_shap_img_dem = mask_positive(q_shap_img_dem, reverse=False)\n",
    "q_shap_nomalized_dem = mask_positive(q_shap_nomalized_dem, reverse=False)\n",
    "q_shap_img_dem = cast_to_float32(q_shap_img_dem)\n",
    "q_shap_nomalized_dem = cast_to_float32(q_shap_nomalized_dem)\n",
    "nib.save(q_shap_img_dem, os.path.join(output_dir, f\"shap_brainmap_ALE_{train_group}_dem.nii.gz\"))\n",
    "nib.save(q_shap_nomalized_dem, os.path.join(output_dir, f\"shap_brainmap_ALE_{train_group}_norm_dem.nii.gz\"))\n",
    "\n",
    "q_shap_nomalized_nc, _ = normalize_image(q_shap_img_nc, max_val=max_val)\n",
    "q_shap_img_nc = mask_positive(q_shap_img_nc, reverse=True)\n",
    "q_shap_nomalized_nc = mask_positive(q_shap_nomalized_nc, reverse=True)\n",
    "q_shap_img_nc = cast_to_float32(q_shap_img_nc)\n",
    "q_shap_nomalized_nc = cast_to_float32(q_shap_nomalized_nc)\n",
    "nib.save(q_shap_img_nc, os.path.join(output_dir, f\"shap_brainmap_ALE_{train_group}_nc.nii.gz\"))\n",
    "nib.save(q_shap_nomalized_nc, os.path.join(output_dir, f\"shap_brainmap_ALE_{train_group}_norm_nc.nii.gz\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880f2ada",
   "metadata": {},
   "source": [
    "##### Create ALE binary map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_path = r'/home/Codes/image_processing/meta_analysis/meta_analysis_all_ALE/meta_analysis_ALE_C05_1k_ALE.nii'\n",
    "ale_mask_path = r'/home/Codes/image_processing/meta_analysis/meta_analysis_all_ALE/meta_analysis_ALE_C05_1k_ALE_mask.nii.gz'\n",
    "create_binary_map(ale_path, ale_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = r'/home/Codes/image_processing/plot_MUSEroi/MNI152_T1_1mm_brain_LPS_filled.nii'\n",
    "ale_path = r'/home/Codes/image_processing/meta_analysis/meta_analysis_all_ALE/meta_analysis_ALE_C05_1k_ALE.nii'\n",
    "ale_cog_path = r'/home/Codes/image_processing/meta_analysis/meta_analysis_all_ALE/meta_analysis_ALE_C05_1k_ALE_mni.nii.gz'\n",
    "\n",
    "coregister_to_template(\n",
    "    ale_path,\n",
    "    template,\n",
    "    ale_cog_path,\n",
    "    False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d59d61",
   "metadata": {},
   "source": [
    "##### Visualize regions based on meta-analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3eda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_coords = [-30, -25, -20, -15, -10, -5, 0, 10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_path = r'/home/Codes/image_processing/meta_analysis/meta_analysis_all_ALE/meta_analysis_ALE_C05_1k_ALE_mni.nii.gz'\n",
    "img_ale_mni = nib.load(ale_path)\n",
    "template = nib.load(r'/home/Codes/image_processing/meta_analysis/plot_MUSEroi/MNI152_T1_1mm_brain_LPS_filled.nii')\n",
    "visualize_roi_map(\n",
    "    img_ale_mni,\n",
    "    template,\n",
    "    vmin=img_ale_mni.get_fdata().min(),\n",
    "    vmax=img_ale_mni.get_fdata().max(),\n",
    "    coords=cut_coords,\n",
    "    cmap='Reds',\n",
    "    title='ALE meta-analysis',\n",
    "    save_path=r'/home/Codes/ad_classification/images/ale_roi.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    (1, 1, 1, 0.0),\n",
    "    (0.9, 0.1, 0.1, 0.2),\n",
    "    (0.9, 0.1, 0.1, 0.5),\n",
    "    (0.9, 0.1, 0.1, 0.8),\n",
    "    (0.9, 0.1, 0.1, 1.0)\n",
    "]\n",
    "smoothed_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_smooth\", colors, N=256)\n",
    "smoothed_cmap.set_under(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f75c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dem_path = rf'/home/Codes/ad_classification/results/shap_map/shap_brainmap_ALE_{train_group}_norm_dem.nii.gz'\n",
    "img_dem = nib.load(image_dem_path)\n",
    "image_nc_path = rf'/home/Codes/ad_classification/results/shap_map/shap_brainmap_ALE_{train_group}_norm_nc.nii.gz'\n",
    "img_nc = nib.load(image_nc_path)\n",
    "\n",
    "visualize_roi_map(\n",
    "    img_dem,\n",
    "    template,\n",
    "    vmin=1e-6,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap=smoothed_cmap,\n",
    "    title=f'Trained on {train_group} population (ALE-based) - Dementia Prediction',\n",
    "    save_path=rf'/home/Codes/ad_classification/images/shap_{train_group}_norm_dem.png',\n",
    ")\n",
    "\n",
    "visualize_roi_map(\n",
    "    img_nc,\n",
    "    template,\n",
    "    vmin=1e-6,\n",
    "    vmax=1,\n",
    "    coords=cut_coords,\n",
    "    cmap='Reds',\n",
    "    title=f'Trained on {train_group} population (ALE-based) - NC Prediction',\n",
    "    save_path=rf'/home/Codes/ad_classification/images/shap_{train_group}_norm_nc.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c2b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62fb189f",
   "metadata": {},
   "source": [
    "#### Visualize SHAP heatmap for individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(r\"/home/Codes/ad_classification\") \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import matplotlib.colors as mcolors\n",
    "from itertools import product\n",
    "\n",
    "from viz_utils import ( \n",
    "    brain_regions,\n",
    "    normalize_image,\n",
    "    mask_positive,\n",
    "    cast_to_float32,\n",
    "    convert_to_template, \n",
    "    visualize_roi_map,\n",
    "    load_folds_from_pickle,\n",
    "    load_folds_from_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_BASE = \"/home/Codes/ad_classification/results/xgb_new\"\n",
    "SHAP_VALUE_DIR = \"/home/Codes/ad_classification/results/shap_values\"\n",
    "CSV_DIRS = {\n",
    "    \"xgb_ssda\": \"/home/Codes/ad_classification/results/xgb_objective_v2_2B\",\n",
    "    \"xgb_regalign\": \"/home/Codes/ad_classification/results/xgb_objective_v2_1B\"\n",
    "}\n",
    "MUSE_DIR = \"/home/Codes/image_processing/plot_MUSEroi\"\n",
    "SAVE_ROOT = \"/home/Codes/ad_classification/images/SHAP_maps\"\n",
    "SCENARIOS = [\"All\", \"NHW\", \"NHA\", \"Hispanic\"]\n",
    "CSV_SCENARIOS = [\"all\", \"nhw\", \"nha\", \"hisp\"]\n",
    "MODEL_TYPES = [\"xgb\", \"xgb_harm\", \"xgb_cr\", \"xgb_kmm\", \"xgb_ssda\", \"xgb_regalign\"]\n",
    "SELECTED_FEATURES = [\"31\", \"47\", \"48\", \"55\", \"170\", \"171\", \"194\", \"200\"]\n",
    "CUT_COORDS = [-30, -25, -20, -15, -10, -5, 0, 10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab59f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\n",
    "    (1, 1, 1, 0.0), (0.9, 0.1, 0.1, 0.2), (0.9, 0.1, 0.1, 0.5),\n",
    "    (0.9, 0.1, 0.1, 0.8), (0.9, 0.1, 0.1, 1.0)\n",
    "]\n",
    "smoothed_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_smooth\", colors, N=256)\n",
    "smoothed_cmap.set_under(\"none\")\n",
    "\n",
    "df_muse = pd.read_csv(os.path.join(MUSE_DIR, \"MUSE_levels.csv\"))\n",
    "template = nib.load(os.path.join(MUSE_DIR, \"MNI152_T1_1mm_brain_LPS_filled.nii\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484799d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Setup\n",
    "model_types = [\"xgb_ssda\",\"xgb_regalign\"]  # or \"xgb_ssda\", \"xgb_regalign\", etc.\n",
    "scenarios = [\"All\", \"NHW\", \"NHA\", \"Hispanic\"]\n",
    "desired_classes = [0,1]   # 1 = Dementia, 0 = NC\n",
    "\n",
    "for model_type, scenario, desired_class in product(model_types,scenarios,desired_classes):\n",
    "\n",
    "    if desired_class:\n",
    "        reverse = False\n",
    "        status = \"Dementia Prediction\"\n",
    "    else:\n",
    "        reverse = False\n",
    "        status = \"NC Prediction\"\n",
    "\n",
    "    # üìÇ File paths\n",
    "    if model_type in (\"xgb_ssda\", \"xgb_regalign\"):\n",
    "        scenario_key = scenario.lower()\n",
    "        if scenario_key == \"hispanic\":\n",
    "            scenario_key = \"hisp\"\n",
    "        scenario_file = f\"scenario_{scenario_key}_shap.pkl\"\n",
    "        shap_path = os.path.join(SHAP_VALUE_DIR, model_type, scenario_file)\n",
    "    else:\n",
    "        scenario_file = f\"NCvsDem_train-{scenario}_*.pkl\"\n",
    "        shap_path = glob.glob(os.path.join(SHAP_VALUE_DIR, model_type, scenario_file))[0]\n",
    "\n",
    "    # Load SHAP values\n",
    "    with open(shap_path, \"rb\") as f:\n",
    "        shap_values_fold = pickle.load(f)\n",
    "\n",
    "    # Load folds\n",
    "    if model_type in (\"xgb_ssda\", \"xgb_regalign\"):\n",
    "        csv_model_dir = CSV_DIRS[model_type]\n",
    "        scenario_key = scenario.lower()\n",
    "        if scenario_key == \"hispanic\":\n",
    "            scenario_key = \"hisp\"\n",
    "        feature_names, y_folds, y_pred_folds, valid_folds = load_folds_from_csv(scenario_key, csv_model_dir)\n",
    "    else:\n",
    "        pkl_candidates = sorted(glob.glob(os.path.join(PKL_BASE, f\"NCvsDem_train-{scenario}_*.pkl\")))\n",
    "        assert pkl_candidates, f\"No PKL found for scenario {scenario}\"\n",
    "        pkl_path = pkl_candidates[0]\n",
    "        feature_names, y_folds, y_pred_folds, valid_folds = load_folds_from_pickle(pkl_path)\n",
    "\n",
    "    # üîÅ SHAP aggregation over folds\n",
    "    fold_means = []\n",
    "    for j, fold in enumerate(shap_values_fold):\n",
    "        feature_means = []\n",
    "        for k in range(len(feature_names)):\n",
    "            valid_idx = valid_folds[j][k]\n",
    "            y_vals = y_folds[j][valid_idx]\n",
    "            y_preds = y_pred_folds[j][valid_idx]\n",
    "            mask = (y_vals == desired_class) & ((y_preds == desired_class) if not reverse else (y_preds == 1 - desired_class))\n",
    "            filtered_idx = np.array(valid_idx)[mask]\n",
    "            if len(filtered_idx):\n",
    "                mean_val = np.mean(fold[filtered_idx, k])\n",
    "            else:\n",
    "                mean_val = np.mean(fold[valid_idx, k])\n",
    "            feature_means.append(mean_val)\n",
    "        fold_means.append(feature_means)\n",
    "    shap_values = np.nanmean(fold_means, axis=0)\n",
    "    if desired_class == 0:\n",
    "        shap_values = -shap_values\n",
    "\n",
    "    # üß† Generate SHAP brain map\n",
    "    shap_img = convert_to_template(shap_values, SELECTED_FEATURES, feature_names, MUSE_DIR, df_muse)\n",
    "    shap_img, _ = normalize_image(shap_img)\n",
    "    shap_img = cast_to_float32(shap_img)\n",
    "    shap_img_masked = mask_positive(shap_img, reverse=reverse)\n",
    "\n",
    "    # üñºÔ∏è Save visualization\n",
    "    save_path = os.path.join(SAVE_ROOT, model_type, f\"shap_heatmap_{scenario.lower()}_{status.replace(' ', '_')}.png\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    visualize_roi_map(\n",
    "        shap_img_masked,\n",
    "        template,\n",
    "        vmin=1e-6,\n",
    "        vmax=1,\n",
    "        coords=CUT_COORDS,\n",
    "        cmap=smoothed_cmap,\n",
    "        title=f\"SHAP Heatmap | {model_type.upper()} | Trained on {scenario.upper()} - {status}\",\n",
    "        save_path=save_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca7358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
